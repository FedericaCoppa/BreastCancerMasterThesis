{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Roi.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3b2079c099014711916b5f249cefd759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4ea6322fac3b41ccaa7f13d7bad30099",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b6b0a099c482485fb1645609aba34635",
              "IPY_MODEL_c9df8f377c74408da9812d95440d25f7"
            ]
          }
        },
        "4ea6322fac3b41ccaa7f13d7bad30099": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6b0a099c482485fb1645609aba34635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_735dfc33a3e64600b8424f78ef7e4492",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 244408911,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 244408911,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb6a0bee29c245989111da49a1095cc0"
          }
        },
        "c9df8f377c74408da9812d95440d25f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_807c917135d9485eaf2670f72824027c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 233M/233M [00:01&lt;00:00, 135MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfe1d06082934067bd75e1f01373926d"
          }
        },
        "735dfc33a3e64600b8424f78ef7e4492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb6a0bee29c245989111da49a1095cc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "807c917135d9485eaf2670f72824027c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfe1d06082934067bd75e1f01373926d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtITqpQavFI7",
        "outputId": "dbd53d0f-87f3-48d6-e21f-aaf099c9e8b0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0koWri6vGJt",
        "outputId": "e3814aeb-d342-4a0b-efbf-fe276cf34778"
      },
      "source": [
        "import os \n",
        "\n",
        "# Set your working directory to a folder in your Google Drive. This way, if your notebook times out,\n",
        "# your files will be saved in your Google Drive!\n",
        "\n",
        "# the base Google Drive directory\n",
        "root_dir = \"/content/drive/My Drive/\"\n",
        "\n",
        "# choose where you want your project files to be saved\n",
        "project_folder = \"tesi2\"\n",
        "\n",
        "def create_and_set_working_directory(project_folder):\n",
        "  # check if your project folder exists. if not, it will be created.\n",
        "  if os.path.isdir(root_dir + project_folder) == False:\n",
        "    os.mkdir(root_dir + project_folder)\n",
        "    print(root_dir + project_folder + ' did not exist but was created.')\n",
        "\n",
        "  # change the OS to use your project folder as the working directory\n",
        "  os.chdir(root_dir + project_folder)\n",
        "\n",
        "  # create a test file to make sure it shows up in the right place\n",
        "  !touch 'new_file_in_working_directory.txt'\n",
        "  print('\\nYour working directory was changed to ' + root_dir + project_folder + \\\n",
        "        \"\\n\\nAn empty text file was created there. You can also run !pwd to confirm the current working directory.\" )\n",
        "\n",
        "create_and_set_working_directory(project_folder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Your working directory was changed to /content/drive/My Drive/tesi2\n",
            "\n",
            "An empty text file was created there. You can also run !pwd to confirm the current working directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3b2079c099014711916b5f249cefd759",
            "4ea6322fac3b41ccaa7f13d7bad30099",
            "b6b0a099c482485fb1645609aba34635",
            "c9df8f377c74408da9812d95440d25f7",
            "735dfc33a3e64600b8424f78ef7e4492",
            "eb6a0bee29c245989111da49a1095cc0",
            "807c917135d9485eaf2670f72824027c",
            "dfe1d06082934067bd75e1f01373926d"
          ]
        },
        "id": "DgadNhDgvG1S",
        "outputId": "464c1a0b-efe4-4093-efa9-9b399ec05198"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import *\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy\n",
        "import os\n",
        "import json \n",
        "\n",
        "\n",
        "modelName = 'AlexNet'\n",
        "PRETRAINED = True\n",
        "n_epochs = 100\n",
        "batch_size = 8\n",
        "learning_rate = 1e-3\n",
        "use_cuda = True\n",
        "\n",
        "JSON_FILE = 'plotdata.json'\n",
        "\n",
        "\n",
        "# Associa modelName ad una classe\n",
        "# senza ancora creare l'oggetto, lo faccio dopo...\n",
        "models = {\n",
        "    'AlexNet': models.alexnet,\n",
        "    'ResNet18': models.resnet18,\n",
        "    'denseNet121': models.densenet121,\n",
        "    'vgg16':models.vgg16,\n",
        "    'googlenet':models.googlenet,\n",
        "    'inception':models.inception_v3,\n",
        "    'shufflenet': models.shufflenet_v2_x1_0\n",
        "}\n",
        "\n",
        "\n",
        "transforms = transforms.Compose(\n",
        "[   \n",
        "    #transforms.RandomVerticalFlip(0.4),\n",
        "    #transforms.RandomHorizontalFlip(0.4), \n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "def pad_collate(batch):\n",
        "    X, y = zip(*batch)\n",
        "    X = list(X)\n",
        "    maxw, maxh = 0, 0 \n",
        "\n",
        "    for img in X:\n",
        "        _, w, h = img.shape\n",
        "        maxw = max(w, maxw)\n",
        "        maxh = max(h, maxh)\n",
        "\n",
        "    for i, img in enumerate(X):\n",
        "        _, w, h = img.shape\n",
        "        diff_w = maxw - w\n",
        "        diff_h = maxh - h\n",
        "        newImg = F.pad(img, (diff_h, 0, diff_w, 0))\n",
        "        X[i] = newImg.unsqueeze(0)\n",
        "    out =  torch.cat(X)\n",
        "    y   =  torch.tensor(y)    \n",
        "    return out, y\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root='roi_train_contrast', transform=transforms)\n",
        "test_dataset = datasets.ImageFolder(root='roi_test_contrast', transform=transforms)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn = pad_collate)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn = pad_collate)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "def imshow(inp, title=None):\n",
        "    \n",
        "    inp = inp.cpu() if device else inp\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    \n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    \n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)\n",
        "    \n",
        "\n",
        "def accuracy(out, labels):\n",
        "    _,pred = torch.max(out, dim=1)\n",
        "    return torch.sum(pred==labels).item()\n",
        "\n",
        "#images, labels = next(iter(train_dataloader)) \n",
        "#print(\"images-size:\", images.shape)\n",
        "\n",
        "#out = torchvision.utils.make_grid(images)\n",
        "#print(\"out-size:\", out.shape)\n",
        "\n",
        "#imshow(out, title=[train_dataset.classes[x] for x in labels])\n",
        "\n",
        "# Qui creo l'oggetto:\n",
        "# per crearlo uso models[modelName] che mi dara' la classe,\n",
        "# e con le parentesi creo l'oggetto, sarebbe equivalente a fare\n",
        "# models.resnet18(), ma in questo modo e' generale perche' invece\n",
        "# di models.resnet18 quello prende la classe giusta in base al nome\n",
        "# che metti in modelName...\n",
        "# poi gli dico se usare il pretrained o no in base alla\n",
        "# variabile PRETRAINED che ho definito in alto\n",
        "net = models[modelName](pretrained=PRETRAINED)\n",
        "print(net)\n",
        "net = net.cuda() if device else net\n",
        "\n",
        "# qui layer finale viene sostituito\n",
        "# quindi ogni volta\n",
        "# tocca andare a trovare il nome giusto (dal print(net)\n",
        "if modelName == 'ResNet18':\n",
        "    num_ftrs = net.fc.in_features\n",
        "    net.fc = nn.Linear(num_ftrs, 2)\n",
        "    if use_cuda: net.fc = net.fc.cuda()\n",
        "\n",
        "elif modelName == 'AlexNet':\n",
        "    num_ftrs = net.classifier[6].in_features\n",
        "    net.classifier[6] = nn.Linear(num_ftrs, 2)\n",
        "    if use_cuda: net.classifier[6] = net.classifier[6].cuda()\n",
        "\n",
        "elif modelName == 'vgg16':\n",
        "    num_ftrs = net.classifier[6].in_features\n",
        "    net.classifier[6] = nn.Linear(num_ftrs, 3)\n",
        "    if use_cuda: net.classifier[6] = net.classifier[6].cuda()\n",
        "\n",
        "elif modelName == 'denseNet121':\n",
        "    num_ftrs = net.classifier.in_features\n",
        "    net.classifier = nn.Linear(num_ftrs, 3)\n",
        "    if use_cuda: net.classifier = net.classifier.cuda()\n",
        "\n",
        "elif modelName == 'googlenet':\n",
        "    num_ftrs = net.fc.in_features\n",
        "    net.fc = nn.Linear(num_ftrs, 3)\n",
        "    if use_cuda: net.fc = net.fc.cuda()\n",
        "\n",
        "elif modelName == 'inception':\n",
        "    num_ftrs = net.fc.in_features\n",
        "    net.fc = nn.Linear(num_ftrs, 3)\n",
        "    if use_cuda: net.fc = net.fc.cuda()\n",
        "\n",
        "elif modelName == 'shufflenet':\n",
        "    num_ftrs = net.fc.in_features\n",
        "    net.fc = nn.Linear(num_ftrs, 3)\n",
        "    if use_cuda: net.fc = net.fc.cuda()\n",
        "    \n",
        "    \n",
        "    \n",
        "     \n",
        "\n",
        "    \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
        "\n",
        "print_every = 10\n",
        "valid_loss_min = np.Inf\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "total_step = len(train_dataloader)\n",
        "\n",
        "print(net)\n",
        "PRETRAINEDtxt = 'Pretrained' if PRETRAINED else 'Base'\n",
        "print(f'Training Model {modelName}{PRETRAINEDtxt}')\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total=0\n",
        "    print(f'Epoch {epoch}\\n')\n",
        "    for batch_idx, (data_, target_) in enumerate(train_dataloader):\n",
        "        data_, target_ = data_.to(device), target_.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = net(data_)\n",
        "        loss = criterion(outputs, target_)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _,pred = torch.max(outputs, dim=1)\n",
        "        correct += torch.sum(pred==target_).item()\n",
        "        total += target_.size(0)\n",
        "        if (batch_idx) % 20 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n",
        "    train_acc.append(100 * correct / total)\n",
        "    train_loss.append(running_loss/total_step)\n",
        "    print(f'\\ntrain-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}')\n",
        "    batch_loss = 0\n",
        "    total_t=0\n",
        "    correct_t=0\n",
        "    with torch.no_grad():\n",
        "        net.eval()\n",
        "        for data_t, target_t in (test_dataloader):\n",
        "            data_t, target_t = data_t.to(device), target_t.to(device)\n",
        "            outputs_t = net(data_t)\n",
        "            #print(outputs_t)\n",
        "            #torch.argmax(outputs_t)\n",
        "            loss_t = criterion(outputs_t, target_t)\n",
        "            batch_loss += loss_t.item()\n",
        "            _,pred_t = torch.max(outputs_t, dim=1)\n",
        "            correct_t += torch.sum(pred_t==target_t).item()\n",
        "            total_t += target_t.size(0)\n",
        "        val_acc.append(100 * correct_t/total_t)\n",
        "        val_loss.append(batch_loss/len(test_dataloader))\n",
        "        network_learned = batch_loss < valid_loss_min\n",
        "        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t/total_t):.4f}\\n')\n",
        "\n",
        "        \n",
        "        if network_learned:\n",
        "            valid_loss_min = batch_loss\n",
        "            torch.save(net.state_dict(), f'models/{modelName}{PRETRAINEDtxt}.pt')\n",
        "            print('Improvement-Detected, save-model')\n",
        "    net.train()\n",
        "\n",
        "fig = plt.figure(figsize=(20,10))\n",
        "plt.title(\"Train-Validation Accuracy\")\n",
        "plt.plot(train_acc, label='train')\n",
        "plt.plot(val_acc, label='validation')\n",
        "plt.xlabel('num_epochs', fontsize=12)\n",
        "plt.ylabel('accuracy', fontsize=12)\n",
        "plt.legend(loc='best')\n",
        "plt.savefig(f'plots/Plot{modelName}{PRETRAINEDtxt}.png')\n",
        "\n",
        "\n",
        "# Salva dati in file JSON (uso sempre lo stesso)\n",
        "with open(JSON_FILE, 'r') as f:\n",
        "    jsonfile = json.load(f)\n",
        "jsonfile[modelName + PRETRAINEDtxt] = {\n",
        "    'train_acc': train_acc,\n",
        "    'val_acc': val_acc,\n",
        "    'train_loss': train_loss,\n",
        "    'val_loss': val_loss,\n",
        "}\n",
        "with open(JSON_FILE, 'w') as f:\n",
        "    json.dump(jsonfile, f)\n",
        "\n",
        "\n",
        "def visualize_model(net, num_images=4):\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure(figsize=(15, 10))\n",
        "    \n",
        "    for i, data in enumerate(test_dataloader):\n",
        "        inputs, labels = data\n",
        "        if use_cuda:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        outputs = net(inputs)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        preds = preds.cpu().numpy() if use_cuda else preds.numpy()\n",
        "        for j in range(inputs.size()[0]):\n",
        "            images_so_far += 1\n",
        "            ax = plt.subplot(2, num_images//2, images_so_far)\n",
        "            ax.axis('off')\n",
        "            ax.set_title('predictes: {}'.format(test_dataset.classes[preds[j]]))\n",
        "            imshow(inputs[j])\n",
        "            \n",
        "            if images_so_far == num_images:\n",
        "                return \n",
        "\n",
        "plt.ion()\n",
        "visualize_model(net)\n",
        "plt.ioff()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b2079c099014711916b5f249cefd759",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=244408911.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "Training Model AlexNetPretrained\n",
            "Epoch 1\n",
            "\n",
            "Epoch [1/100], Step [0/124], Loss: 0.6330\n",
            "Epoch [1/100], Step [20/124], Loss: 0.6563\n",
            "Epoch [1/100], Step [40/124], Loss: 0.6493\n",
            "Epoch [1/100], Step [60/124], Loss: 0.6978\n",
            "Epoch [1/100], Step [80/124], Loss: 0.7379\n",
            "Epoch [1/100], Step [100/124], Loss: 0.6650\n",
            "Epoch [1/100], Step [120/124], Loss: 0.6584\n",
            "\n",
            "train-loss: 0.7001, train-acc: 49.3428\n",
            "validation loss: 0.6963, validation acc: 49.3671\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 2\n",
            "\n",
            "Epoch [2/100], Step [0/124], Loss: 0.6812\n",
            "Epoch [2/100], Step [20/124], Loss: 0.5280\n",
            "Epoch [2/100], Step [40/124], Loss: 0.7613\n",
            "Epoch [2/100], Step [60/124], Loss: 0.6756\n",
            "Epoch [2/100], Step [80/124], Loss: 0.6934\n",
            "Epoch [2/100], Step [100/124], Loss: 0.7381\n",
            "Epoch [2/100], Step [120/124], Loss: 0.6498\n",
            "\n",
            "train-loss: 0.7025, train-acc: 49.7472\n",
            "validation loss: 0.6985, validation acc: 52.7426\n",
            "\n",
            "Epoch 3\n",
            "\n",
            "Epoch [3/100], Step [0/124], Loss: 0.6871\n",
            "Epoch [3/100], Step [20/124], Loss: 0.7591\n",
            "Epoch [3/100], Step [40/124], Loss: 0.6493\n",
            "Epoch [3/100], Step [60/124], Loss: 0.6777\n",
            "Epoch [3/100], Step [80/124], Loss: 0.7166\n",
            "Epoch [3/100], Step [100/124], Loss: 0.7282\n",
            "Epoch [3/100], Step [120/124], Loss: 0.6186\n",
            "\n",
            "train-loss: 0.6988, train-acc: 55.6117\n",
            "validation loss: 0.7104, validation acc: 48.9451\n",
            "\n",
            "Epoch 4\n",
            "\n",
            "Epoch [4/100], Step [0/124], Loss: 0.7316\n",
            "Epoch [4/100], Step [20/124], Loss: 0.6837\n",
            "Epoch [4/100], Step [40/124], Loss: 0.7355\n",
            "Epoch [4/100], Step [60/124], Loss: 0.7452\n",
            "Epoch [4/100], Step [80/124], Loss: 0.6781\n",
            "Epoch [4/100], Step [100/124], Loss: 0.6921\n",
            "Epoch [4/100], Step [120/124], Loss: 0.8081\n",
            "\n",
            "train-loss: 0.6968, train-acc: 53.2861\n",
            "validation loss: 0.7142, validation acc: 48.1013\n",
            "\n",
            "Epoch 5\n",
            "\n",
            "Epoch [5/100], Step [0/124], Loss: 0.7274\n",
            "Epoch [5/100], Step [20/124], Loss: 0.6463\n",
            "Epoch [5/100], Step [40/124], Loss: 0.7845\n",
            "Epoch [5/100], Step [60/124], Loss: 0.6979\n",
            "Epoch [5/100], Step [80/124], Loss: 0.5978\n",
            "Epoch [5/100], Step [100/124], Loss: 0.6800\n",
            "Epoch [5/100], Step [120/124], Loss: 0.8933\n",
            "\n",
            "train-loss: 0.6947, train-acc: 54.6006\n",
            "validation loss: 0.7126, validation acc: 49.7890\n",
            "\n",
            "Epoch 6\n",
            "\n",
            "Epoch [6/100], Step [0/124], Loss: 0.7002\n",
            "Epoch [6/100], Step [20/124], Loss: 0.5688\n",
            "Epoch [6/100], Step [40/124], Loss: 0.7192\n",
            "Epoch [6/100], Step [60/124], Loss: 0.6568\n",
            "Epoch [6/100], Step [80/124], Loss: 0.7321\n",
            "Epoch [6/100], Step [100/124], Loss: 0.7033\n",
            "Epoch [6/100], Step [120/124], Loss: 0.6871\n",
            "\n",
            "train-loss: 0.6929, train-acc: 55.5106\n",
            "validation loss: 0.7103, validation acc: 51.0549\n",
            "\n",
            "Epoch 7\n",
            "\n",
            "Epoch [7/100], Step [0/124], Loss: 0.6187\n",
            "Epoch [7/100], Step [20/124], Loss: 0.6694\n",
            "Epoch [7/100], Step [40/124], Loss: 0.6885\n",
            "Epoch [7/100], Step [60/124], Loss: 0.6575\n",
            "Epoch [7/100], Step [80/124], Loss: 0.7432\n",
            "Epoch [7/100], Step [100/124], Loss: 0.6673\n",
            "Epoch [7/100], Step [120/124], Loss: 0.7194\n",
            "\n",
            "train-loss: 0.6902, train-acc: 58.3418\n",
            "validation loss: 0.7117, validation acc: 49.7890\n",
            "\n",
            "Epoch 8\n",
            "\n",
            "Epoch [8/100], Step [0/124], Loss: 0.6487\n",
            "Epoch [8/100], Step [20/124], Loss: 0.6490\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-bed5e81fc475>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtarget_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuI_Bws_Ci9m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}